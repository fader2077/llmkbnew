# src/inspector.py
"""
Structure diagnosis (Phase 3) - å­¸è¡“ç´šå°ˆæ¥­ç‰ˆ
å°è£ç‚º GraphInspector é¡ï¼Œé¿å… import æ™‚è‡ªå‹•åŸ·è¡Œ
"""
from typing import Dict, Any, List, Optional
import sys

class GraphInspector:
    """
    åœ–è­œå“è³ªæª¢æŸ¥å“¡ (Graph Inspector)
    è² è²¬åŸ·è¡Œå­¸è¡“ç´šå®Œæ•´åº¦é©—è­‰èˆ‡å“è³ªå ±å‘Šã€‚
    """
    def __init__(self, driver):
        self.driver = driver

    def run_basic_diagnosis(self, verbose: bool = True) -> Dict[str, Any]:
        """
        åŸ·è¡ŒåŸºæœ¬çš„åœ–è­œçµ±è¨ˆè¨ºæ–·
        
        Returns:
            Dict åŒ…å«: chunks, entities, relations_total, mentions_count, 
                      relation_count, density, avg_degree
        """
        results = {}
        
        with self.driver.session() as session:
            if verbose:
                print("\n" + "="*70)
                print("ğŸ” æ­¥é©Ÿä¸€ï¼šæ¨™æº–åŒ–è¨ˆæ•¸é©—è­‰")
                print("="*70)
            
            # A. è¨ˆç®—æ‰€æœ‰é¡å‹ç¯€é»çš„ç¸½æ•¸
            total_nodes = session.run("MATCH (n) RETURN count(n) AS cnt").single()["cnt"]
            if verbose:
                print(f"A. æ‰€æœ‰é¡å‹ç¯€é»ç¸½æ•¸ï¼š{total_nodes:,}")
            
            # B. è¨ˆç®—æ‰€æœ‰ Entity ç¯€é»çš„ç¸½æ•¸
            total_entities = session.run("MATCH (e:Entity) RETURN count(e) AS cnt").single()["cnt"]
            if verbose:
                print(f"B. Entity ç¯€é»ç¸½æ•¸ï¼š{total_entities:,}")
            
            # C. è¨ˆç®—æ‰€æœ‰ Chunk ç¯€é»çš„ç¸½æ•¸
            total_chunks = session.run("MATCH (c:Chunk) RETURN count(c) AS cnt").single()["cnt"]
            if verbose:
                print(f"C. Chunk ç¯€é»ç¸½æ•¸ï¼š{total_chunks:,}")
            
            # D. è¨ˆç®—æ‰€æœ‰é—œä¿‚çš„ç¸½æ•¸ï¼ˆæ¨™æº–æ–¹æ³•ï¼‰
            total_relationships = session.run("MATCH ()-[r]-() RETURN count(r) AS cnt").single()["cnt"]
            if verbose:
                print(f"D. æ‰€æœ‰é—œä¿‚ç¸½æ•¸ï¼ˆé›™å‘è¨ˆæ•¸ï¼‰ï¼š{total_relationships:,}")
            
            # E. è¨ˆç®— RELATION é¡å‹é—œä¿‚çš„ç¸½æ•¸ï¼ˆå–®å‘è¨ˆæ•¸ï¼‰
            relation_type_count = session.run("MATCH ()-[r:RELATION]->() RETURN count(r) AS cnt").single()["cnt"]
            if verbose:
                print(f"E. RELATION é¡å‹é—œä¿‚ç¸½æ•¸ï¼ˆå–®å‘ï¼‰ï¼š{relation_type_count:,}")
            
            # F. è¨ˆç®— MENTIONS é¡å‹é—œä¿‚çš„ç¸½æ•¸ï¼ˆå–®å‘è¨ˆæ•¸ï¼‰
            mentions_count = session.run("MATCH ()-[r:MENTIONS]->() RETURN count(r) AS cnt").single()["cnt"]
            if verbose:
                print(f"F. MENTIONS é¡å‹é—œä¿‚ç¸½æ•¸ï¼ˆå–®å‘ï¼‰ï¼š{mentions_count:,}")
            
            # è¨ˆç®—å¯†åº¦å’Œå¹³å‡åº¦æ•¸
            # æ³¨æ„ï¼šå°æ–¼ RAG ç³»çµ±ï¼Œæˆ‘å€‘é—œæ³¨çš„æ˜¯ã€Œæœ‰æ•ˆå¯†åº¦ã€(E/V)ï¼Œè€Œéå­¸è¡“å®šç¾©çš„ E/(V*(V-1))
            # å­¸è¡“å¯†åº¦å°å¤§åœ–æœƒè¶¨è¿‘æ–¼ 0ï¼Œä¸é©åˆä½œç‚ºå„ªåŒ–ç›®æ¨™
            academic_density = (relation_type_count / (total_entities * (total_entities - 1))) if total_entities > 1 else 0
            effective_density = (relation_type_count / total_entities) if total_entities > 0 else 0  # å³ avg_degree / 2
            avg_degree = (2 * relation_type_count / total_entities) if total_entities > 0 else 0
            
            results = {
                "chunks": total_chunks,
                "entities": total_entities,
                "relations_total": relation_type_count + mentions_count,
                "mentions_count": mentions_count,
                "relation_count": relation_type_count,
                "density": effective_density,  # ä½¿ç”¨æœ‰æ•ˆå¯†åº¦ä»£æ›¿å­¸è¡“å¯†åº¦
                "academic_density": academic_density,  # ä¿ç•™å­¸è¡“å¯†åº¦ä¾›åƒè€ƒ
                "avg_degree": avg_degree,
                "total_nodes": total_nodes,
                "total_relationships_bidirectional": total_relationships
            }
            
            if verbose:
                print("\n" + "="*70)
                print("ğŸ“Š è¨ºæ–·çµæœï¼š")
                print(f"  â€¢ å¯¦é«”ç¯€é»ï¼š{total_entities:,}")
                print(f"  â€¢ èªç¾©é—œä¿‚ï¼ˆRELATIONï¼‰ï¼š{relation_type_count:,}")
                print(f"  â€¢ ä¾†æºè¿½æº¯ï¼ˆMENTIONSï¼‰ï¼š{mentions_count:,}")
                print(f"  â€¢ é—œä¿‚ç¸½è¨ˆï¼š{relation_type_count + mentions_count:,}")
                print(f"  â€¢ æœ‰æ•ˆå¯†åº¦ï¼ˆE/Vï¼‰ï¼š{effective_density:.3f}  ğŸ‘ˆ RAG å„ªåŒ–ç›®æ¨™")
                print(f"  â€¢ å¹³å‡åº¦æ•¸ï¼ˆ2E/Vï¼‰ï¼š{avg_degree:.2f}")
                print(f"  â€¢ å­¸è¡“å¯†åº¦ï¼ˆåƒè€ƒï¼‰ï¼š{academic_density:.6f}")
                print(f"  â€¢ é›™å‘è¨ˆæ•¸é©—è­‰ï¼š{total_relationships:,} (æ‡‰ç‚º {2 * (relation_type_count + mentions_count):,})")
                print("="*70 + "\n")
        
        return results
    
    def run_integrity_analysis(self, verbose: bool = True) -> Dict[str, Any]:
        """
        åŸ·è¡Œé—œä¿‚å®Œæ•´æ€§åˆ†æï¼ˆæª¢æ¸¬éºå¤±é—œä¿‚ï¼‰
        """
        results = {}
        
        with self.driver.session() as session:
            if verbose:
                print("\n" + "="*70)
                print("ğŸ” æ­¥é©ŸäºŒï¼šé—œä¿‚å®Œæ•´æ€§åˆ†æ")
                print("="*70 + "\n")
            
            total_entities = session.run("MATCH (e:Entity) RETURN count(e) AS cnt").single()["cnt"]
            
            # A. æª¢æŸ¥æœ‰å¤šå°‘å¯¦é«”æ²’æœ‰ä»»ä½• RELATION
            isolated_entities = session.run("""
                MATCH (e:Entity)
                WHERE NOT (e)-[:RELATION]-()
                RETURN count(e) AS cnt
            """).single()["cnt"]
            
            if verbose:
                print(f"A. å­¤ç«‹å¯¦é«”ï¼ˆç„¡ RELATIONï¼‰ï¼š{isolated_entities:,} / {total_entities:,} ({isolated_entities/total_entities*100:.2f}%)")
            
            results = {
                "isolated_entities": isolated_entities,
                "total_entities": total_entities,
                "isolated_ratio": (isolated_entities/total_entities*100) if total_entities > 0 else 0
            }
            
            if verbose:
                print("\n" + "="*70)
        
        return results

    def run_comprehensive_quality_check(self, dataset_id: str, verbose: bool = True) -> Dict[str, Any]:
        """
        åŸ·è¡Œå®Œæ•´çš„å­¸è¡“ç´šåœ–è­œè³ªé‡æª¢é©—
        
        æª¢é©—ç¶­åº¦ï¼š
        1. çµæ§‹å®Œæ•´åº¦ (Completeness)
        2. é€£æ¥è³ªé‡ (Connectivity Quality)
        3. å¯¦é«”åº¦æ•¸åˆ†å¸ƒ (Degree Distribution)
        4. é—œä¿‚é¡å‹å¤šæ¨£æ€§ (Relation Type Diversity)
        5. æ½›åœ¨è³ªé‡å•é¡Œ (Quality Issues)
        
        åƒè€ƒæ¨™æº–ï¼š
        - Paulheim (2017), "Knowledge Graph Refinement"
        - Zaveri et al. (2016), "Quality Assessment for Linked Data"
        """
        results = {
            "basic_metrics": {},
            "connectivity_quality": {},
            "degree_distribution": {},
            "relation_diversity": {},
            "quality_issues": {},
            "overall_grade": ""
        }
        
        if verbose:
            print("\n" + "="*100)
            print("ğŸ”¬ çŸ¥è­˜åœ–è­œè³ªé‡èˆ‡å®Œæ•´åº¦å­¸è¡“ç´šæª¢é©—å ±å‘Š")
            print("="*100)
            print("ğŸ“š æª¢é©—æ¨™æº–ï¼šPaulheim (2017) + Zaveri et al. (2016)")
            print("="*100)
        
        with self.driver.session() as session:
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # ç¬¬ä¸€éƒ¨åˆ†ï¼šåŸºç¤æŒ‡æ¨™
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            if verbose:
                print("\nğŸ“Š ä¸€ã€åŸºç¤çµæ§‹æŒ‡æ¨™")
                print("-"*100)
            
            entity_count = session.run("MATCH (e:Entity) RETURN count(e) AS cnt").single()["cnt"]
            relation_count = session.run("MATCH ()-[r:RELATION]->() RETURN count(r) AS cnt").single()["cnt"]
            chunk_count = session.run("MATCH (c:Chunk {dataset: $dataset}) RETURN count(c) AS cnt", dataset=dataset_id).single()["cnt"]
            mentions_count = session.run("MATCH ()-[m:MENTIONS]->() RETURN count(m) AS cnt").single()["cnt"]
            
            # è¨ˆç®—é—œä¿‚å¯†åº¦ï¼ˆæ¯å€‹å¯¦é«”å¹³å‡æœ‰å¤šå°‘é—œä¿‚ï¼‰
            density = (relation_count / entity_count) if entity_count > 0 else 0.0
            
            # è¨ˆç®—å¹³å‡åº¦æ•¸ï¼ˆé›™å‘è¨ˆæ•¸ï¼‰
            avg_degree_result = session.run("""
                MATCH (e:Entity)
                OPTIONAL MATCH (e)-[r:RELATION]-()
                WITH e, count(r) AS degree
                RETURN avg(degree) AS avg_degree
            """).single()
            avg_degree = avg_degree_result["avg_degree"] if avg_degree_result else 0.0
            
            results["basic_metrics"] = {
                "entities": entity_count,
                "relations": relation_count,
                "chunks": chunk_count,
                "mentions": mentions_count,
                "density": density,
                "avg_degree": avg_degree
            }
            
            if verbose:
                print(f"  â€¢ å¯¦é«”ç¯€é»æ•¸ï¼š{entity_count:,}")
                print(f"  â€¢ èªç¾©é—œä¿‚æ•¸ï¼š{relation_count:,}")
                print(f"  â€¢ æ–‡æœ¬ Chunksï¼š{chunk_count:,}")
                print(f"  â€¢ MENTIONS é€£æ¥ï¼š{mentions_count:,}")
                print(f"  â€¢ é—œä¿‚å¯†åº¦ (R/E)ï¼š{density:.3f}")
                print(f"  â€¢ å¹³å‡åº¦æ•¸ï¼š{avg_degree:.2f}")
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # ç¬¬äºŒéƒ¨åˆ†ï¼šé€£æ¥è³ªé‡åˆ†æ
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            if verbose:
                print(f"\nğŸ”— äºŒã€é€£æ¥è³ªé‡åˆ†æ")
                print("-"*100)
            
            # 1. å­¤ç«‹å¯¦é«”ï¼ˆåº¦æ•¸ = 0ï¼‰
            isolated_entities = session.run("""
                MATCH (e:Entity)
                WHERE NOT (e)-[:RELATION]-()
                RETURN count(e) AS cnt
            """).single()["cnt"]
            isolated_percent = (isolated_entities / entity_count * 100) if entity_count > 0 else 0
            
            # 2. å¼±é€£æ¥å¯¦é«”ï¼ˆåº¦æ•¸ 1-3ï¼‰
            weak_entities = session.run("""
                MATCH (e:Entity)-[r:RELATION]-()
                WITH e, count(r) AS degree
                WHERE degree >= 1 AND degree <= 3
                RETURN count(e) AS cnt
            """).single()["cnt"]
            weak_percent = (weak_entities / entity_count * 100) if entity_count > 0 else 0
            
            # 3. ä¸­åº¦é€£æ¥å¯¦é«”ï¼ˆåº¦æ•¸ 4-9ï¼‰
            moderate_entities = session.run("""
                MATCH (e:Entity)-[r:RELATION]-()
                WITH e, count(r) AS degree
                WHERE degree >= 4 AND degree <= 9
                RETURN count(e) AS cnt
            """).single()["cnt"]
            moderate_percent = (moderate_entities / entity_count * 100) if entity_count > 0 else 0
            
            # 4. å¼·é€£æ¥å¯¦é«”ï¼ˆåº¦æ•¸ >= 10ï¼‰
            strong_entities = session.run("""
                MATCH (e:Entity)-[r:RELATION]-()
                WITH e, count(r) AS degree
                WHERE degree >= 10
                RETURN count(e) AS cnt
            """).single()["cnt"]
            strong_percent = (strong_entities / entity_count * 100) if entity_count > 0 else 0
            
            results["connectivity_quality"] = {
                "isolated": {"count": isolated_entities, "percent": isolated_percent},
                "weak": {"count": weak_entities, "percent": weak_percent},
                "moderate": {"count": moderate_entities, "percent": moderate_percent},
                "strong": {"count": strong_entities, "percent": strong_percent}
            }
            
            if verbose:
                print(f"  1. å­¤ç«‹å¯¦é«”ï¼ˆåº¦æ•¸=0ï¼‰ï¼š{isolated_entities:,} ({isolated_percent:.1f}%)")
                print(f"     {'âœ… å„ªç§€' if isolated_percent < 5 else 'âš ï¸ éœ€æ³¨æ„' if isolated_percent < 15 else 'âŒ éœ€æ”¹é€²'}")
                print(f"  2. å¼±é€£æ¥å¯¦é«”ï¼ˆåº¦æ•¸1-3ï¼‰ï¼š{weak_entities:,} ({weak_percent:.1f}%)")
                print(f"     {'âœ… å„ªç§€' if weak_percent < 30 else 'âš ï¸ éœ€æ³¨æ„' if weak_percent < 50 else 'âŒ éœ€æ”¹é€²'}")
                print(f"  3. ä¸­åº¦é€£æ¥å¯¦é«”ï¼ˆåº¦æ•¸4-9ï¼‰ï¼š{moderate_entities:,} ({moderate_percent:.1f}%)")
                print(f"  4. å¼·é€£æ¥å¯¦é«”ï¼ˆåº¦æ•¸â‰¥10ï¼‰ï¼š{strong_entities:,} ({strong_percent:.1f}%)")
                print(f"     {'âœ… å„ªç§€' if strong_percent >= 10 else 'âš ï¸ å¾…å„ªåŒ–' if strong_percent >= 5 else 'âŒ éœ€æ”¹é€²'}")
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # ç¬¬ä¸‰éƒ¨åˆ†ï¼šå¯¦é«”åº¦æ•¸åˆ†å¸ƒçµ±è¨ˆ
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            if verbose:
                print(f"\nğŸ“ˆ ä¸‰ã€å¯¦é«”åº¦æ•¸åˆ†å¸ƒ")
                print("-"*100)
            
            degree_distribution = session.run("""
                MATCH (e:Entity)
                OPTIONAL MATCH (e)-[r:RELATION]-()
                WITH e, count(r) AS degree
                RETURN degree, count(e) AS entity_count
                ORDER BY degree DESC
                LIMIT 20
            """).data()
            
            results["degree_distribution"] = degree_distribution
            
            if verbose:
                print(f"  åº¦æ•¸åˆ†å¸ƒï¼ˆå‰ 20ï¼‰ï¼š")
                for dist in degree_distribution[:10]:
                    print(f"    åº¦æ•¸ {dist['degree']:3d}ï¼š{dist['entity_count']:,} å€‹å¯¦é«”")
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # ç¬¬å››éƒ¨åˆ†ï¼šé—œä¿‚é¡å‹å¤šæ¨£æ€§
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            if verbose:
                print(f"\nğŸ¨ å››ã€é—œä¿‚é¡å‹å¤šæ¨£æ€§")
                print("-"*100)
            
            relation_type_count = session.run("""
                MATCH ()-[r:RELATION]->()
                RETURN count(DISTINCT r.type) AS cnt
            """).single()["cnt"]
            
            relation_types = session.run("""
                MATCH ()-[r:RELATION]->()
                RETURN r.type AS relation_type, count(r) AS cnt
                ORDER BY cnt DESC
                LIMIT 10
            """).data()
            
            results["relation_diversity"] = {
                "total_types": relation_type_count,
                "top_types": relation_types
            }
            
            if verbose:
                print(f"  â€¢ é—œä¿‚é¡å‹ç¸½æ•¸ï¼š{relation_type_count}")
                print(f"  â€¢ å‰ 10 ç¨®é—œä¿‚é¡å‹ï¼š")
                for idx, rel in enumerate(relation_types, 1):
                    percent = (rel['cnt'] / relation_count * 100) if relation_count > 0 else 0
                    print(f"    {idx:2d}. {rel['relation_type']:<40s} {rel['cnt']:>6,} ({percent:>5.1f}%)")
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # ç¬¬äº”éƒ¨åˆ†ï¼šæ½›åœ¨è³ªé‡å•é¡Œæª¢æ¸¬
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            if verbose:
                print(f"\nâš ï¸  äº”ã€æ½›åœ¨è³ªé‡å•é¡Œæª¢æ¸¬")
                print("-"*100)
            
            issues_found = []
            
            # æª¢æ¸¬ 1ï¼šè‡ªç’°é—œä¿‚
            self_loops = session.run("""
                MATCH (e:Entity)-[r:RELATION]->(e)
                RETURN count(r) AS cnt
            """).single()["cnt"]
            if self_loops > 0:
                issues_found.append(f"ç™¼ç¾ {self_loops} å€‹è‡ªç’°é—œä¿‚")
            
            # æª¢æ¸¬ 2ï¼šé‡è¤‡é—œä¿‚
            duplicate_relations = session.run("""
                MATCH (h:Entity)-[r:RELATION]->(t:Entity)
                WITH h, t, r.type AS rel_type, count(r) AS cnt
                WHERE cnt > 1
                RETURN count(*) AS dup_cnt
            """).single()["dup_cnt"]
            if duplicate_relations > 0:
                issues_found.append(f"ç™¼ç¾ {duplicate_relations} çµ„é‡è¤‡é—œä¿‚")
            
            # æª¢æ¸¬ 3ï¼šè¶…é•·å¯¦é«”åç¨±
            long_entities = session.run("""
                MATCH (e:Entity)
                WHERE size(e.name) > 50
                RETURN count(e) AS cnt
            """).single()["cnt"]
            if long_entities > 0:
                issues_found.append(f"ç™¼ç¾ {long_entities} å€‹è¶…é•·å¯¦é«”åç¨±ï¼ˆ>50å­—å…ƒï¼‰")
            
            # æª¢æ¸¬ 4ï¼šç©ºå±¬æ€§
            empty_chunks_relations = session.run("""
                MATCH ()-[r:RELATION]->()
                WHERE r.chunks IS NULL OR r.chunks = []
                RETURN count(r) AS cnt
            """).single()["cnt"]
            if empty_chunks_relations > 0:
                issues_found.append(f"ç™¼ç¾ {empty_chunks_relations} å€‹é—œä¿‚ç¼ºå°‘ä¾†æºæ¨™è¨˜")
            
            results["quality_issues"] = {
                "self_loops": self_loops,
                "duplicate_relations": duplicate_relations,
                "long_entities": long_entities,
                "empty_chunks_relations": empty_chunks_relations,
                "issues_list": issues_found
            }
            
            if verbose:
                if issues_found:
                    for issue in issues_found:
                        print(f"  âš ï¸  {issue}")
                else:
                    print("  âœ… æœªç™¼ç¾æ˜é¡¯è³ªé‡å•é¡Œ")
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # æœ€çµ‚è©•ç´š
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            if verbose:
                print(f"\n{'='*100}")
                print(f"ğŸ† æœ€çµ‚è³ªé‡è©•ç´š")
                print(f"{'='*100}")
            
            score = 0
            max_score = 7
            
            # è©•åˆ†ç¶­åº¦
            if density >= 2.0:
                score += 1
                density_status = "âœ…"
            elif density >= 1.5:
                score += 0.5
                density_status = "âš ï¸"
            else:
                density_status = "âŒ"
            
            if avg_degree >= 4.0:
                score += 1
                degree_status = "âœ…"
            elif avg_degree >= 2.5:
                score += 0.5
                degree_status = "âš ï¸"
            else:
                degree_status = "âŒ"
            
            if isolated_percent < 5:
                score += 1
                isolated_status = "âœ…"
            elif isolated_percent < 15:
                score += 0.5
                isolated_status = "âš ï¸"
            else:
                isolated_status = "âŒ"
            
            if weak_percent < 30:
                score += 1
                weak_status = "âœ…"
            elif weak_percent < 50:
                score += 0.5
                weak_status = "âš ï¸"
            else:
                weak_status = "âŒ"
            
            if strong_percent >= 10:
                score += 1
                strong_status = "âœ…"
            elif strong_percent >= 5:
                score += 0.5
                strong_status = "âš ï¸"
            else:
                strong_status = "âŒ"
            
            if relation_type_count >= 50:
                score += 1
                diversity_status = "âœ…"
            elif relation_type_count >= 30:
                score += 0.5
                diversity_status = "âš ï¸"
            else:
                diversity_status = "âŒ"
            
            if len(issues_found) == 0:
                score += 1
                quality_status = "âœ…"
            elif len(issues_found) <= 2:
                score += 0.5
                quality_status = "âš ï¸"
            else:
                quality_status = "âŒ"
            
            if verbose:
                print(f"  {density_status} é—œä¿‚å¯†åº¦ â‰¥ 2.0ï¼š{density:.3f}")
                print(f"  {degree_status} å¹³å‡åº¦æ•¸ â‰¥ 4.0ï¼š{avg_degree:.2f}")
                print(f"  {isolated_status} å­¤ç«‹å¯¦é«” < 5%ï¼š{isolated_percent:.1f}%")
                print(f"  {weak_status} å¼±é€£æ¥å¯¦é«” < 30%ï¼š{weak_percent:.1f}%")
                print(f"  {strong_status} å¼·é€£æ¥å¯¦é«” â‰¥ 10%ï¼š{strong_percent:.1f}%")
                print(f"  {diversity_status} é—œä¿‚é¡å‹ â‰¥ 50ï¼š{relation_type_count}")
                print(f"  {quality_status} ç„¡è³ªé‡å•é¡Œï¼š{'æ˜¯' if len(issues_found) == 0 else 'å¦'}")
                print(f"\n  ç¸½åˆ†ï¼š{score:.1f}/{max_score}")
            
            if score >= 6.5:
                grade = "A+ å“è¶Š"
            elif score >= 5.5:
                grade = "A å„ªç§€"
            elif score >= 4.5:
                grade = "B è‰¯å¥½"
            elif score >= 3.5:
                grade = "C åŠæ ¼"
            else:
                grade = "D å¾…æ”¹é€²"
            
            results["overall_grade"] = grade
            results["score"] = score
            results["max_score"] = max_score
            
            if verbose:
                print(f"  ç­‰ç´šï¼š{grade}")
                print(f"{'='*100}\n")
        
        return results

    def check_quality_issues(self) -> Dict[str, int]:
        """
        æª¢æŸ¥åœ–è­œè³ªé‡å•é¡Œï¼Œè¿”å›çµ±è¨ˆæ•¸æ“š
        
        Returns:
            Dict åŒ…å«:
                - self_loops: è‡ªç’°é—œä¿‚æ•¸é‡
                - duplicate_relations: é‡è¤‡é—œä¿‚çµ„æ•¸
                - empty_chunks: ç¼ºå¤±ä¾†æºæ¨™è¨˜çš„é—œä¿‚æ•¸é‡
                - isolated_entities: å­¤ç«‹å¯¦é«”æ•¸é‡
                - weak_entities: å¼±é€£æ¥å¯¦é«”æ•¸é‡ï¼ˆåº¦æ•¸1-3ï¼‰
        """
        results = {}
        
        with self.driver.session() as session:
            # 1. æª¢æŸ¥è‡ªç’°é—œä¿‚
            self_loops = session.run("""
                MATCH (e:Entity)-[r:RELATION]->(e)
                RETURN count(r) AS cnt
            """).single()["cnt"]
            
            # 2. æª¢æŸ¥é‡è¤‡é—œä¿‚
            duplicate_relations = session.run("""
                MATCH (h:Entity)-[r:RELATION]->(t:Entity)
                WITH h, r.type AS rel_type, t, collect(r) AS rels
                WHERE size(rels) > 1
                RETURN count(*) AS cnt
            """).single()["cnt"]
            
            # 3. æª¢æŸ¥ç¼ºå¤±ä¾†æºæ¨™è¨˜çš„é—œä¿‚
            empty_chunks = session.run("""
                MATCH ()-[r:RELATION]->()
                WHERE r.chunks IS NULL OR r.chunks = [] OR size(r.chunks) = 0
                RETURN count(r) AS cnt
            """).single()["cnt"]
            
            # 4. æª¢æŸ¥å­¤ç«‹å¯¦é«”
            isolated_entities = session.run("""
                MATCH (e:Entity)
                WHERE NOT (e)-[:RELATION]-()
                RETURN count(e) AS cnt
            """).single()["cnt"]
            
            # 5. æª¢æŸ¥å¼±é€£æ¥å¯¦é«”ï¼ˆåº¦æ•¸1-3ï¼‰
            weak_entities = session.run("""
                MATCH (e:Entity)
                OPTIONAL MATCH (e)-[r:RELATION]-()
                WITH e, count(r) AS degree
                WHERE degree >= 1 AND degree <= 3
                RETURN count(e) AS cnt
            """).single()["cnt"]
            
            results = {
                "self_loops": self_loops,
                "duplicate_relations": duplicate_relations,
                "empty_chunks": empty_chunks,
                "isolated_entities": isolated_entities,
                "weak_entities": weak_entities
            }
        
        return results
