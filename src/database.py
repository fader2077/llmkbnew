# src/database.py
"""
Neo4j è³‡æ–™åº«é€£æ¥èˆ‡ç®¡ç†æ¨¡çµ„

æä¾›ï¼š
- Neo4jConnector é¡åˆ¥ï¼šå°è£ Neo4j é€£æ¥
- clean_databaseï¼šè³‡æ–™æ¸…ç†å‡½æ•¸
- ensure_vector_indexï¼šå‘é‡ç´¢å¼•å»ºç«‹
- ensure_fulltext_indexï¼šå…¨æ–‡ç´¢å¼•å»ºç«‹
"""

from typing import Dict
from neo4j import GraphDatabase


class Neo4jConnector:
    """Neo4j è³‡æ–™åº«é€£æ¥å™¨"""
    
    def __init__(self, uri: str, auth: tuple):
        """
        åˆå§‹åŒ–é€£æ¥
        
        Args:
            uri: Neo4j é€£æ¥ URI (ä¾‹å¦‚: "bolt://localhost:7687")
            auth: èªè­‰å…ƒçµ„ (username, password)
        """
        self.driver = GraphDatabase.driver(uri, auth=auth)
        self.uri = uri
    
    def close(self):
        """é—œé–‰é€£æ¥"""
        if self.driver:
            self.driver.close()
    
    def get_driver(self):
        """ç²å–åº•å±¤ driver å°è±¡"""
        return self.driver
    
    def verify_connectivity(self):
        """é©—è­‰é€£æ¥æ˜¯å¦æ­£å¸¸"""
        self.driver.verify_connectivity()
        print(f"âœ… Neo4j é€£æ¥æˆåŠŸ: {self.uri}")
    
    def __enter__(self):
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        self.close()


def clean_database(driver, dataset_id: str, clean_all: bool = False) -> Dict[str, int]:
    """
    æ¸…ç† Neo4j è³‡æ–™åº«ä¸­çš„èˆŠè³‡æ–™ã€‚
    
    Args:
        driver: Neo4j GraphDatabase driver
        dataset_id: è¦æ¸…ç†çš„è³‡æ–™é›† ID
        clean_all: è‹¥ç‚º Trueï¼Œæ¸…ç†æ‰€æœ‰è³‡æ–™ï¼›å¦å‰‡åƒ…æ¸…ç†æŒ‡å®š dataset_id çš„è³‡æ–™
    
    Returns:
        åˆªé™¤çš„ç¯€é»å’Œé—œä¿‚çµ±è¨ˆ
    """
    with driver.session() as session:
        if clean_all:
            print("ğŸ—‘ï¸ æ¸…ç†æ‰€æœ‰è³‡æ–™...")
            # åˆªé™¤æ‰€æœ‰ç¯€é»å’Œé—œä¿‚
            deleted_relations = session.run("MATCH ()-[r]->() DELETE r RETURN count(r) AS cnt").single()["cnt"]
            deleted_nodes = session.run("MATCH (n) DELETE n RETURN count(n) AS cnt").single()["cnt"]
            print(f"  âœ… å·²åˆªé™¤ {deleted_nodes} å€‹ç¯€é», {deleted_relations} å€‹é—œä¿‚")
            
            return {
                "deleted_chunks": deleted_nodes,
                "deleted_mentions": deleted_relations,
                "deleted_entities": 0,
                "deleted_relations": 0,
            }
        else:
            print(f"ğŸ—‘ï¸ æ¸…ç† dataset_id = '{dataset_id}' çš„è³‡æ–™...")
            
            # åˆªé™¤èˆ‡æŒ‡å®š dataset ç›¸é—œçš„ Chunk ç¯€é»åŠå…¶é—œä¿‚
            deleted_mentions = session.run(
                """
                MATCH (c:Chunk {dataset: $dataset})-[m:MENTIONS]->(:Entity)
                DELETE m
                RETURN count(m) AS cnt
                """,
                dataset=dataset_id,
            ).single()["cnt"]
            
            # æ¸…ç†å­¤ç«‹çš„ Entity å’Œ RELATION
            deleted_relations = session.run(
                """
                MATCH (e:Entity)
                WHERE NOT (e)<-[:MENTIONS]-(:Chunk)
                MATCH (e)-[r:RELATION]-()
                DELETE r
                RETURN count(r) AS cnt
                """
            ).single()["cnt"]
            
            deleted_entities = session.run(
                """
                MATCH (e:Entity)
                WHERE NOT (e)<-[:MENTIONS]-(:Chunk)
                  AND NOT (e)-[:RELATION]-()
                DELETE e
                RETURN count(e) AS cnt
                """
            ).single()["cnt"]
            
            deleted_chunks = session.run(
                """
                MATCH (c:Chunk {dataset: $dataset})
                DELETE c
                RETURN count(c) AS cnt
                """,
                dataset=dataset_id,
            ).single()["cnt"]
            
            print(f"  âœ… å·²åˆªé™¤ {deleted_chunks} å€‹ Chunks")
            print(f"  âœ… å·²åˆªé™¤ {deleted_mentions} å€‹ MENTIONS é—œä¿‚")
            print(f"  âœ… å·²åˆªé™¤ {deleted_entities} å€‹å­¤ç«‹ Entities")
            print(f"  âœ… å·²åˆªé™¤ {deleted_relations} å€‹å­¤ç«‹ RELATIONS")
            
            return {
                "deleted_chunks": deleted_chunks,
                "deleted_mentions": deleted_mentions,
                "deleted_entities": deleted_entities,
                "deleted_relations": deleted_relations,
            }


def ensure_entity_index(driver) -> None:
    """
    ç‚º Entity ç¯€é»çš„ name å±¬æ€§å‰µå»ºç´¢å¼•ï¼ˆé—œéµæ€§èƒ½å„ªåŒ–ï¼‰
    
    é€™èƒ½è®“ MERGE (e:Entity {name: $name}) æ“ä½œæå‡ 10 å€ä»¥ä¸Šçš„é€Ÿåº¦ã€‚
    
    Args:
        driver: Neo4j driver
    """
    with driver.session() as session:
        try:
            # å‰µå»º Entity name çš„å”¯ä¸€ç´„æŸï¼ˆè‡ªå‹•åŒ…å«ç´¢å¼•ï¼‰
            session.run(
                "CREATE CONSTRAINT entity_name_unique IF NOT EXISTS "
                "FOR (e:Entity) REQUIRE e.name IS UNIQUE"
            )
            print("  âœ… Entity name å”¯ä¸€ç´„æŸå·²å‰µå»ºï¼ˆå«ç´¢å¼•ï¼‰")
        except Exception as e:
            # å¦‚æœå”¯ä¸€ç´„æŸå·²å­˜åœ¨æˆ–å¤±æ•—ï¼Œå˜—è©¦å‰µå»ºæ™®é€šç´¢å¼•
            try:
                session.run(
                    "CREATE INDEX entity_name_index IF NOT EXISTS "
                    "FOR (e:Entity) ON (e.name)"
                )
                print("  âœ… Entity name ç´¢å¼•å·²å‰µå»º")
            except Exception as e2:
                print(f"  âš ï¸  Entity ç´¢å¼•å‰µå»ºè­¦å‘Š: {e2}")


def ensure_vector_index(
    driver, 
    name: str, 
    label: str, 
    prop: str, 
    dimensions: int, 
    similarity: str = "cosine"
) -> None:
    """
    ç¢ºä¿å‘é‡ç´¢å¼•å­˜åœ¨
    
    Args:
        driver: Neo4j driver
        name: ç´¢å¼•åç¨±
        label: ç¯€é»æ¨™ç±¤
        prop: å±¬æ€§åç¨±
        dimensions: å‘é‡ç¶­åº¦
        similarity: ç›¸ä¼¼åº¦å‡½æ•¸ ("cosine", "euclidean")
    """
    with driver.session() as session:
        # æª¢æŸ¥ç´¢å¼•æ˜¯å¦å·²å­˜åœ¨
        existing = session.run("SHOW INDEXES").data()
        if any(idx.get("name") == name for idx in existing):
            print(f"  âœ… å‘é‡ç´¢å¼• '{name}' å·²å­˜åœ¨")
            return
        
        # å‰µå»ºå‘é‡ç´¢å¼•
        cypher = f"""
        CREATE VECTOR INDEX {name}
        FOR (n:{label}) ON (n.{prop})
        OPTIONS {{ indexConfig: {{ `vector.dimensions`: {dimensions}, `vector.similarity_function`: '{similarity}' }} }}
        """
        session.run(cypher)
        session.run("CALL db.awaitIndexes()")
        print(f"  âœ… å·²å‰µå»ºå‘é‡ç´¢å¼• '{name}' (ç¶­åº¦={dimensions}, ç›¸ä¼¼åº¦={similarity})")


def ensure_fulltext_index(driver, name: str, label: str, prop: str = "text") -> bool:
    """
    ç¢ºä¿å…¨æ–‡ç´¢å¼•å­˜åœ¨
    
    Args:
        driver: Neo4j driver
        name: ç´¢å¼•åç¨±
        label: ç¯€é»æ¨™ç±¤
        prop: å±¬æ€§åç¨±
    
    Returns:
        ç´¢å¼•æ˜¯å¦å¯ç”¨
    """
    with driver.session() as session:
        # æª¢æŸ¥ç´¢å¼•æ˜¯å¦å·²å­˜åœ¨
        existing = session.run("SHOW INDEXES").data()
        if any(idx.get("name") == name for idx in existing):
            print(f"  âœ… å…¨æ–‡ç´¢å¼• '{name}' å·²å­˜åœ¨")
            return True
        
        # å‰µå»ºå…¨æ–‡ç´¢å¼•
        try:
            session.run(
                f"CREATE FULLTEXT INDEX {name} FOR (n:{label}) ON EACH [n.{prop}]"
            )
            session.run("CALL db.awaitIndexes()")
            print(f"  âœ… å·²å‰µå»ºå…¨æ–‡ç´¢å¼• '{name}'")
            return True
        except Exception as e:
            print(f"  âš ï¸ å…¨æ–‡ç´¢å¼•å‰µå»ºå¤±æ•—: {e}")
            return False
