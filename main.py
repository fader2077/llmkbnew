# main.py
"""
Graph RAG Pipeline - ç»Ÿä¸€æ‰§è¡Œå…¥å£

å®Œæ•´æµç¨‹ï¼š
Phase 1: ç´¢å¼•æ¶ˆèæµ‹è¯•
Phase 2: å›¾è°±æ„å»º
Phase 3: å›¾è°±ä¼˜åŒ–ä¸è¯Šæ–­  
Phase 4: æ£€ç´¢æ¶ˆèæµ‹è¯•
"""

import sys
from pathlib import Path
from ollama import Client

# ç¡®ä¿å¯ä»¥ import src
sys.path.insert(0, str(Path(__file__).parent))

from config import CONFIG, KNOWLEDGE_BASE_PATH, QUESTION_DATASET_PATH
from src.database import Neo4jConnector, clean_database
from src.models import OllamaVectorEmbedder
from src.builder import GraphBuilder
from src.inspector import GraphInspector
#from src.optimizer import EnhanceGraphConnectivity
from src.retrieval import RetrievalEngine, test_retrieval
from src.experiments import RetrievalAblationRunner, IndexingAblationRunner


def print_menu():
    """æ˜¾ç¤ºä¸»èœå•"""
    print("\n" + "="*70)
    print("ğŸš€ Graph RAG Pipeline - ä¸»èœå•")
    print("="*70)
    print()
    print("ğŸ“š é˜¶æ®µé€‰æ‹©:")
    print("  1. ğŸ—ï¸  Phase 1: ç´¢å¼•æ¶ˆèå®éªŒ (Indexing Ablation)")
    print("  2. ğŸ—ï¸  Phase 2: æ„å»ºçŸ¥è¯†å›¾è°± (Build Graph)")
    print("  3. ğŸ” Phase 3a: å®Œæ•´åœ–è­œè¨ºæ–· (Comprehensive Diagnosis)")
    print("  4. âš¡ Phase 3b: åœ–è­œæ“´å¢å„ªåŒ– (Graph Augmentation Optimization)")
    print("  5. ğŸ§ª Phase 4: æ£€ç´¢æ¶ˆèå®éªŒ (Retrieval Ablation)")
    print("  6. ğŸ¯ å¿«é€Ÿæµ‹è¯•æ£€ç´¢ (Quick Test Retrieval)")
    print("  9. ğŸ—‘ï¸  æ¸…ç†æ•°æ®åº“ (Clean Database)")
    print("  0. âŒ é€€å‡º (Exit)")
    print()
    print("="*70)


def main():
    """ä¸»ç¨‹åºå…¥å£"""
    print("ğŸ”Œ åˆå§‹åŒ–è¿æ¥...")
    
    # 1. è¿æ¥æ•°æ®åº“
    try:
        db = Neo4jConnector(
            CONFIG["infrastructure"]["neo4j_uri"],
            CONFIG["infrastructure"]["neo4j_auth"]
        )
        db.verify_connectivity()
        driver = db.get_driver()
    except Exception as e:
        print(f"âŒ Neo4j è¿æ¥å¤±è´¥: {e}")
        print(f"è¯·ç¡®ä¿ Neo4j æ­£åœ¨è¿è¡Œ: {CONFIG['infrastructure']['neo4j_uri']}")
        return
    
    # 2. è¿æ¥ Ollama
    try:
        ollama_client = Client(host=CONFIG["infrastructure"]["ollama_host"])
        # ç®€å•æµ‹è¯•è¿æ¥
        ollama_client.list()
        print(f"âœ… Ollama è¿æ¥æˆåŠŸ: {CONFIG['infrastructure']['ollama_host']}")
    except Exception as e:
        print(f"âŒ Ollama è¿æ¥å¤±è´¥: {e}")
        print(f"è¯·ç¡®ä¿ Ollama æ­£åœ¨è¿è¡Œ: {CONFIG['infrastructure']['ollama_host']}")
        db.close()
        return
    
    # ä¸»å¾ªç¯
    try:
        while True:
            print_menu()
            choice = input("è¯·é€‰æ‹©æ“ä½œ (0-6, 9): ").strip()
            
            if choice == "0":
                print("\nğŸ‘‹ å†è§ï¼")
                break
            
            elif choice == "1":
                # Phase 1: ç´¢å¼•æ¶ˆèå®éªŒ
                print("\n" + "="*70)
                print("ğŸ—ï¸  Phase 1: ç´¢å¼•æ¶ˆèå®éªŒ")
                print("="*70)
                print("âš ï¸  æ­¤æ“ä½œä¼šè‡ªåŠ¨æ¸…ç©ºå¹¶é‡å»ºæ•°æ®åº“ï¼Œæµ‹è¯•ä¸åŒçš„ Chunk Size é…ç½®")
                print()
                
                confirm = input("ç¡®è®¤ç»§ç»­? (yes/no): ").strip().lower()
                if confirm != "yes":
                    print("âŒ å·²å–æ¶ˆ")
                    continue
                
                # è®€å– config.py ä¸­çš„ç´¢å¼•æ¶ˆèç¶²æ ¼ï¼ˆindexing_gridï¼‰
                # è‹¥ CONFIG ä¸­ä¸å­˜åœ¨ï¼Œä½¿ç”¨å®‰å…¨çš„å›é€€å€¼
                chunk_configs = CONFIG.get("indexing_grid", [
                    {"chunk_size": 2048, "overlap": 512},
                ])
                
                try:
                    indexing_runner = IndexingAblationRunner(driver, ollama_client)
                    indexing_runner.run_experiment(
                        text_path=KNOWLEDGE_BASE_PATH,
                        chunk_configs=chunk_configs,
                        questions_path=QUESTION_DATASET_PATH,
                        max_questions=150
                    )
                    print("\nâœ… Phase 1 å®Œæˆï¼")
                except Exception as e:
                    print(f"\nâŒ Phase 1 å¤±è´¥: {e}")
                    import traceback
                    traceback.print_exc()
            
            elif choice == "2":
                # Phase 2: æ„å»ºå›¾è°±
                print("\n" + "="*70)
                print("ğŸ—ï¸  å¼€å§‹æ„å»ºçŸ¥è¯†å›¾è°±...")
                print("="*70)
                
                if not KNOWLEDGE_BASE_PATH.exists():
                    print(f"âŒ çŸ¥è¯†åº“æ–‡ä»¶ä¸å­˜åœ¨: {KNOWLEDGE_BASE_PATH}")
                    continue
                
                try:
                    builder = GraphBuilder(driver, ollama_client)
                    builder.build_graph(KNOWLEDGE_BASE_PATH)
                    print("\nâœ… å›¾è°±æ„å»ºå®Œæˆï¼")
                except Exception as e:
                    print(f"\nâŒ æ„å»ºå¤±è´¥: {e}")
                    import traceback
                    traceback.print_exc()
            
            elif choice == "3":
                # Phase 3a: å®Œæ•´è¨ºæ–·
                print("\n" + "="*70)
                print("ğŸ” Phase 3a: å®Œæ•´åœ–è­œè¨ºæ–· (å­¸è¡“ç´š)")
                print("="*70)
                print("æª¢é©—ç¶­åº¦ï¼šçµæ§‹å®Œæ•´åº¦ã€é€£æ¥è³ªé‡ã€åº¦æ•¸åˆ†å¸ƒã€é—œä¿‚å¤šæ¨£æ€§ã€è³ªé‡å•é¡Œ")
                print()
                
                try:
                    inspector = GraphInspector(driver)
                    
                    # åŸ·è¡Œå®Œæ•´çš„å­¸è¡“ç´šè¨ºæ–·
                    results = inspector.run_comprehensive_quality_check(
                        dataset_id=CONFIG["infrastructure"]["dataset_id"],
                        verbose=True
                    )
                    
                    print("\nâœ… è¨ºæ–·å®Œæˆï¼")
                    print(f"\nğŸ“‹ è¨ºæ–·æ‘˜è¦ï¼š")
                    print(f"  â€¢ å¯¦é«”ç¸½æ•¸ï¼š{results['basic_metrics']['entities']:,}")
                    print(f"  â€¢ é—œä¿‚ç¸½æ•¸ï¼š{results['basic_metrics']['relations']:,}")
                    print(f"  â€¢ é—œä¿‚å¯†åº¦ï¼š{results['basic_metrics']['density']:.3f}")
                    print(f"  â€¢ å¹³å‡åº¦æ•¸ï¼š{results['basic_metrics']['avg_degree']:.2f}")
                    print(f"  â€¢ å­¤ç«‹å¯¦é«”ï¼š{results['connectivity_quality']['isolated']['count']:,} ({results['connectivity_quality']['isolated']['percent']:.1f}%)")
                    print(f"  â€¢ å¼±é€£æ¥å¯¦é«”ï¼ˆåº¦æ•¸1-3ï¼‰ï¼š{results['connectivity_quality']['weak']['count']:,} ({results['connectivity_quality']['weak']['percent']:.1f}%)")
                    print(f"  â€¢ è³ªé‡è©•ç´šï¼š{results['overall_grade']}")
                    
                except Exception as e:
                    print(f"\nâŒ è¨ºæ–·å¤±æ•—: {e}")
                    import traceback
                    traceback.print_exc()
            
            elif choice == "4":
                # Phase 3b: å¼±å¯¦é«”æ“´å¢å„ªåŒ–
                print("\n" + "="*70)
                print("âš¡ Phase 3b: å¼±å¯¦é«”æ“´å¢å„ªåŒ–")
                print("="*70)
                print("å„ªåŒ–ç­–ç•¥ï¼š")
                print("  0. è³ªé‡å•é¡Œä¿®å¾©ï¼ˆè‡ªç’°ã€é‡è¤‡ã€ç¼ºå¤±ä¾†æºï¼‰")
                print("  1. å¯¦é«”å°é½Šåˆä½µï¼ˆå»é‡ï¼‰")
                print("  2. å¼±é€£æ¥å¯¦é«”å…¨å±€é—œä¿‚æ¨ç†ï¼ˆåº¦æ•¸1-3ï¼‰")
                print("  3. å‡è¨­æ€§å•é¡Œé—œä¿‚å¯†é›†åŒ–ï¼ˆä½å¯†åº¦Chunksï¼‰")
                print("  4. åŸºç¤é—œä¿‚å¼·åŒ–ï¼ˆäºŒæ¬¡æŠ½å–ï¼‰")
                print("  5. å­¤ç«‹é»æ¸…ç†")
                print()
                print("âš ï¸  æ³¨æ„ï¼šåªå°ç¾æœ‰å¯¦é«”å»ºç«‹é—œä¿‚ï¼Œä¸å‰µå»ºæ–°å¯¦é«”")
                print()
                
                # è®“ç”¨æˆ¶é¸æ“‡åŸ·è¡Œå“ªäº›ç­–ç•¥
                print("è«‹é¸æ“‡åŸ·è¡Œç­–ç•¥ï¼ˆå¯å¤šé¸ï¼Œç”¨é€—è™Ÿåˆ†éš”ï¼Œå¦‚ 0,1,2,3ï¼‰ï¼š")
                strategy_choice = input("ç­–ç•¥é¸é … (0-5 æˆ– 'all'): ").strip().lower()
                
                if strategy_choice == "":
                    print("âŒ å·²å–æ¶ˆ")
                    continue
                
                # è§£æé¸æ“‡
                if strategy_choice == "all":
                    strategies = [0, 1, 2, 3, 4, 5]
                else:
                    try:
                        strategies = [int(s.strip()) for s in strategy_choice.split(",")]
                    except:
                        print("âŒ ç„¡æ•ˆè¼¸å…¥")
                        continue
                
                confirm = input("ç¢ºèªåŸ·è¡Œ? (yes/no): ").strip().lower()
                if confirm != "yes":
                    print("âŒ å·²å–æ¶ˆ")
                    continue
                
                from src.optimizer import GraphOptimizer
                try:
                    optimizer = GraphOptimizer(
                        driver=driver,
                        client=ollama_client,
                        model=CONFIG["models"]["llm_model"]
                    )
                    
                    print("\n" + "="*70)
                    print("é–‹å§‹åŸ·è¡Œå„ªåŒ–æµç¨‹...")
                    print("="*70)
                    
                    # åŸ·è¡Œå„ªåŒ–å‰è¨ºæ–·
                    print("\nğŸ“Š å„ªåŒ–å‰ç‹€æ…‹...")
                    inspector = GraphInspector(driver)
                    before_stats = inspector.run_basic_diagnosis(verbose=False)
                    
                    # å®šç¾©è‡ªå‹•åœæ­¢é–€æª»
                    thresholds = {
                        'min_density': 2.0,           # æœ€å°å¯†åº¦
                        'max_weak_percent': 30.0,     # å¼±é€£æ¥å¯¦é«”æ¯”ä¾‹ä¸Šé™
                        'max_isolated_percent': 5.0,  # å­¤ç«‹å¯¦é«”æ¯”ä¾‹ä¸Šé™
                        'max_self_loops': 0,          # è‡ªç’°é—œä¿‚ä¸Šé™
                        'max_duplicates': 0,          # é‡è¤‡é—œä¿‚ä¸Šé™
                        'max_empty_chunks': 100       # ç¼ºå¤±ä¾†æºæ¨™è¨˜ä¸Šé™
                    }
                    
                    print("\nğŸ¯ è‡ªå‹•åœæ­¢é–€æª»è¨­å®šï¼š")
                    print(f"  â€¢ æœ€å°å¯†åº¦ï¼š{thresholds['min_density']}")
                    print(f"  â€¢ å¼±é€£æ¥å¯¦é«”æ¯”ä¾‹ä¸Šé™ï¼š{thresholds['max_weak_percent']}%")
                    print(f"  â€¢ å­¤ç«‹å¯¦é«”æ¯”ä¾‹ä¸Šé™ï¼š{thresholds['max_isolated_percent']}%")
                    print(f"  â€¢ è‡ªç’°é—œä¿‚ä¸Šé™ï¼š{thresholds['max_self_loops']}")
                    print(f"  â€¢ é‡è¤‡é—œä¿‚ä¸Šé™ï¼š{thresholds['max_duplicates']}")
                    print(f"  â€¢ ç¼ºå¤±ä¾†æºæ¨™è¨˜ä¸Šé™ï¼š{thresholds['max_empty_chunks']}")
                    
                    # åŸ·è¡Œé¸å®šçš„ç­–ç•¥
                    if 0 in strategies:
                        print("\nğŸ”§ ç­–ç•¥ 0ï¼šè³ªé‡å•é¡Œä¿®å¾©")
                        quality_results = optimizer.fix_quality_issues()
                        print(f"  â€¢ ç§»é™¤è‡ªç’°é—œä¿‚ï¼š{quality_results['self_loops_removed']}")
                        print(f"  â€¢ åˆä½µé‡è¤‡é—œä¿‚ï¼š{quality_results['duplicate_relations_merged']}")
                        print(f"  â€¢ ä¿®å¾©ç¼ºå¤±ä¾†æºï¼š{quality_results['empty_chunks_fixed']}")
                        
                        # æª¢æŸ¥è³ªé‡é–€æª»
                        if (quality_results['self_loops_removed'] == 0 and 
                            quality_results['duplicate_relations_merged'] == 0 and 
                            quality_results['empty_chunks_fixed'] <= thresholds['max_empty_chunks']):
                            print("  âœ… è³ªé‡å•é¡Œå·²é”æ¨™ï¼")
                    
                    if 1 in strategies:
                        print("\nğŸ§© ç­–ç•¥ 1ï¼šå¯¦é«”å°é½Šåˆä½µ")
                        optimizer.merge_synonym_entities()
                    
                    if 2 in strategies:
                        print("\nğŸ§  ç­–ç•¥ 2ï¼šå¼±é€£æ¥å¯¦é«”å…¨å±€é—œä¿‚æ¨ç†")
                        infer_results = optimizer.infer_global_relations(
                            min_degree=1,
                            max_degree=3,
                            max_inferences_per_entity=5,
                            batch_size=10
                        )
                        print(f"  â€¢ è™•ç†å¯¦é«”æ•¸ï¼š{infer_results['processed_entities']}")
                        print(f"  â€¢ æ¨ç†é—œä¿‚æ•¸ï¼š{infer_results['inferred_relations']}")
                    
                    if 3 in strategies:
                        print("\nğŸ’¡ ç­–ç•¥ 3ï¼šå‡è¨­æ€§å•é¡Œé—œä¿‚å¯†é›†åŒ–")
                        densify_results = optimizer.densify_relations_with_questions(
                            dataset_id=CONFIG["infrastructure"]["dataset_id"],
                            target_chunks=100,
                            temperature=0.0
                        )
                        print(f"  â€¢ è™•ç† Chunksï¼š{densify_results['processed_chunks']}")
                        print(f"  â€¢ æ–°å¢é—œä¿‚ï¼š{densify_results['new_relations']}")
                    
                    if 4 in strategies:
                        print("\nğŸ”— ç­–ç•¥ 4ï¼šåŸºç¤é—œä¿‚å¼·åŒ–")
                        optimizer.enhance_connectivity(CONFIG["infrastructure"]["dataset_id"])
                    
                    if 5 in strategies:
                        print("\nâœ‚ï¸  ç­–ç•¥ 5ï¼šå­¤ç«‹é»æ¸…ç†")
                        optimizer.prune_isolated_nodes()
                    
                    # åŸ·è¡Œå„ªåŒ–å¾Œè¨ºæ–·
                    print("\nğŸ“Š å„ªåŒ–å¾Œç‹€æ…‹...")
                    after_stats = inspector.run_basic_diagnosis(verbose=False)
                    
                    # ç²å–è³ªé‡çµ±è¨ˆ
                    quality_stats = inspector.check_quality_issues()
                    
                    # å°æ¯”çµæœ
                    print("\n" + "="*70)
                    print("ğŸ“ˆ å„ªåŒ–æ•ˆæœå°æ¯”")
                    print("="*70)
                    print(f"å¯¦é«”æ•¸ï¼š{before_stats['entities']:,} â†’ {after_stats['entities']:,} ({after_stats['entities']-before_stats['entities']:+,})")
                    print(f"é—œä¿‚æ•¸ï¼š{before_stats['relation_count']:,} â†’ {after_stats['relation_count']:,} ({after_stats['relation_count']-before_stats['relation_count']:+,})")
                    print(f"å¯†åº¦ï¼š{before_stats['density']:.3f} â†’ {after_stats['density']:.3f} ({after_stats['density']-before_stats['density']:+.3f})")
                    print(f"å¹³å‡åº¦æ•¸ï¼š{before_stats['avg_degree']:.2f} â†’ {after_stats['avg_degree']:.2f} ({after_stats['avg_degree']-before_stats['avg_degree']:+.2f})")
                    
                    # æª¢æŸ¥æ˜¯å¦é”åˆ°é–€æª»
                    print("\n" + "="*70)
                    print("ğŸ¯ é–€æª»é”æˆæª¢æŸ¥")
                    print("="*70)
                    
                    thresholds_met = []
                    thresholds_not_met = []
                    
                    # æª¢æŸ¥å¯†åº¦
                    if after_stats['density'] >= thresholds['min_density']:
                        thresholds_met.append(f"âœ… å¯†åº¦ï¼š{after_stats['density']:.3f} â‰¥ {thresholds['min_density']}")
                    else:
                        thresholds_not_met.append(f"âŒ å¯†åº¦ï¼š{after_stats['density']:.3f} < {thresholds['min_density']}")
                    
                    # æª¢æŸ¥å¼±é€£æ¥å¯¦é«”æ¯”ä¾‹
                    weak_percent = (quality_stats['weak_entities'] / after_stats['entities'] * 100) if after_stats['entities'] > 0 else 0
                    if weak_percent <= thresholds['max_weak_percent']:
                        thresholds_met.append(f"âœ… å¼±é€£æ¥å¯¦é«”ï¼š{weak_percent:.1f}% â‰¤ {thresholds['max_weak_percent']}%")
                    else:
                        thresholds_not_met.append(f"âŒ å¼±é€£æ¥å¯¦é«”ï¼š{weak_percent:.1f}% > {thresholds['max_weak_percent']}%")
                    
                    # æª¢æŸ¥å­¤ç«‹å¯¦é«”æ¯”ä¾‹
                    isolated_percent = (quality_stats['isolated_entities'] / after_stats['entities'] * 100) if after_stats['entities'] > 0 else 0
                    if isolated_percent <= thresholds['max_isolated_percent']:
                        thresholds_met.append(f"âœ… å­¤ç«‹å¯¦é«”ï¼š{isolated_percent:.1f}% â‰¤ {thresholds['max_isolated_percent']}%")
                    else:
                        thresholds_not_met.append(f"âŒ å­¤ç«‹å¯¦é«”ï¼š{isolated_percent:.1f}% > {thresholds['max_isolated_percent']}%")
                    
                    # æª¢æŸ¥è³ªé‡å•é¡Œ
                    if quality_stats['self_loops'] <= thresholds['max_self_loops']:
                        thresholds_met.append(f"âœ… è‡ªç’°é—œä¿‚ï¼š{quality_stats['self_loops']} â‰¤ {thresholds['max_self_loops']}")
                    else:
                        thresholds_not_met.append(f"âŒ è‡ªç’°é—œä¿‚ï¼š{quality_stats['self_loops']} > {thresholds['max_self_loops']}")
                    
                    if quality_stats['duplicate_relations'] <= thresholds['max_duplicates']:
                        thresholds_met.append(f"âœ… é‡è¤‡é—œä¿‚ï¼š{quality_stats['duplicate_relations']} â‰¤ {thresholds['max_duplicates']}")
                    else:
                        thresholds_not_met.append(f"âŒ é‡è¤‡é—œä¿‚ï¼š{quality_stats['duplicate_relations']} > {thresholds['max_duplicates']}")
                    
                    if quality_stats['empty_chunks'] <= thresholds['max_empty_chunks']:
                        thresholds_met.append(f"âœ… ç¼ºå¤±ä¾†æºï¼š{quality_stats['empty_chunks']} â‰¤ {thresholds['max_empty_chunks']}")
                    else:
                        thresholds_not_met.append(f"âŒ ç¼ºå¤±ä¾†æºï¼š{quality_stats['empty_chunks']} > {thresholds['max_empty_chunks']}")
                    
                    # é¡¯ç¤ºçµæœ
                    for item in thresholds_met:
                        print(item)
                    for item in thresholds_not_met:
                        print(item)
                    
                    print("="*70)
                    
                    if len(thresholds_not_met) == 0:
                        print("\nğŸ‰ æ‰€æœ‰é–€æª»å·²é”æˆï¼å„ªåŒ–è‡ªå‹•åœæ­¢ã€‚")
                    else:
                        print(f"\nâš ï¸  é‚„æœ‰ {len(thresholds_not_met)} å€‹é–€æª»æœªé”æˆï¼Œå»ºè­°ç¹¼çºŒå„ªåŒ–ã€‚")
                    
                    print("\nâœ… Phase 3b å„ªåŒ–å®Œæˆï¼")
                    
                except Exception as e:
                    print(f"\nâŒ å„ªåŒ–å¤±æ•—: {e}")
                    import traceback
                    traceback.print_exc()
            
            elif choice == "5":
                # Phase 4: æ£€ç´¢æ¶ˆèå®éªŒ
                print("\n" + "="*70)
                print("ğŸ§ª Phase 4: æ£€ç´¢æ¶ˆèå®éªŒ")
                print("="*70)
                
                if not QUESTION_DATASET_PATH.exists():
                    print(f"âŒ é—®é¢˜æ•°æ®é›†ä¸å­˜åœ¨: {QUESTION_DATASET_PATH}")
                    continue
                
                print(f"ğŸ“š é—®é¢˜æ•°æ®é›†: {QUESTION_DATASET_PATH}")
                print(f"ğŸ¯ æµ‹è¯•é…ç½®:")
                print(f"   Hops: {CONFIG['retrieval_grid']['hop_counts']}")
                print(f"   Top-K: {CONFIG['retrieval_grid']['top_k_values']}")
                print(f"   æœ€å¤šé—®é¢˜æ•°: {CONFIG['retrieval_grid']['max_questions']}")
                print()
                
                confirm = input("ç¡®è®¤è¿è¡Œå®Œæ•´å®éªŒ? (yes/no): ").strip().lower()
                if confirm != "yes":
                    print("âŒ å·²å–æ¶ˆ")
                    continue
                
                try:
                    runner = RetrievalAblationRunner(driver, ollama_client)
                    results = runner.run_experiment(
                        questions_path=QUESTION_DATASET_PATH,
                        hop_values=CONFIG['retrieval_grid']['hop_counts'],
                        top_k_values=CONFIG['retrieval_grid']['top_k_values'],
                        max_questions=CONFIG['retrieval_grid']['max_questions']
                    )
                    print("\nâœ… å®éªŒå®Œæˆï¼")
                except Exception as e:
                    print(f"\nâŒ å®éªŒå¤±è´¥: {e}")
                    import traceback
                    traceback.print_exc()
            
            elif choice == "6":
                # å¿«é€Ÿæµ‹è¯•æ£€ç´¢
                print("\n" + "="*70)
                print("ğŸ¯ å¿«é€Ÿæµ‹è¯•æ£€ç´¢")
                print("="*70)
                
                question = input("è¯·è¾“å…¥é—®é¢˜ (ç›´æ¥å›è½¦ä½¿ç”¨é»˜è®¤é—®é¢˜): ").strip()
                if not question:
                    question = "What are the symptoms of goat disease?"
                    print(f"  ä½¿ç”¨é»˜è®¤é—®é¢˜: {question}")
                
                try:
                    test_retrieval(driver, ollama_client, question)
                except Exception as e:
                    print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
                    import traceback
                    traceback.print_exc()
            
            elif choice == "9":
                # æ¸…ç†æ•°æ®åº“
                print("\n" + "="*70)
                print("ğŸ—‘ï¸  æ¸…ç†æ•°æ®åº“")
                print("="*70)
                print()
                print("è¯·é€‰æ‹©æ¸…ç†èŒƒå›´:")
                print("  1. æ¸…ç†å½“å‰ dataset")
                print(f"     (dataset_id: {CONFIG['infrastructure']['dataset_id']})")
                print("  2. æ¸…ç†æ‰€æœ‰æ•°æ® (âš ï¸  å±é™©æ“ä½œ)")
                print("  0. å–æ¶ˆ")
                print()
                
                clean_choice = input("é€‰æ‹© (0-2): ").strip()
                
                if clean_choice == "0":
                    print("âŒ å·²å–æ¶ˆ")
                    continue
                elif clean_choice == "1":
                    confirm = input(f"ç¡®è®¤æ¸…ç† dataset '{CONFIG['infrastructure']['dataset_id']}'? (yes/no): ").strip().lower()
                    if confirm == "yes":
                        try:
                            stats = clean_database(driver, CONFIG["infrastructure"]["dataset_id"], clean_all=False)
                            print("\nâœ… æ¸…ç†å®Œæˆï¼")
                        except Exception as e:
                            print(f"\nâŒ æ¸…ç†å¤±è´¥: {e}")
                elif clean_choice == "2":
                    confirm = input("âš ï¸  ç¡®è®¤æ¸…ç†æ‰€æœ‰æ•°æ®? è¾“å…¥ 'yes' ç¡®è®¤: ").strip().lower()
                    if confirm == "yes":
                        try:
                            stats = clean_database(driver, "", clean_all=True)
                            print("\nâœ… æ¸…ç†å®Œæˆï¼")
                        except Exception as e:
                            print(f"\nâŒ æ¸…ç†å¤±è´¥: {e}")
                    else:
                        print("âŒ å·²å–æ¶ˆ")
                else:
                    print("âŒ æ— æ•ˆé€‰æ‹©")
            
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ 0-5 æˆ– 9")
            
            input("\næŒ‰ Enter ç»§ç»­...")
    
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨é€€å‡º...")
    
    finally:
        # æ¸…ç†èµ„æº
        db.close()
        print("âœ… è¿æ¥å·²å…³é—­")


if __name__ == "__main__":
    main()
